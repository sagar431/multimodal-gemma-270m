# Training Configuration
training:
  # Training hyperparameters - adjusted for longer sequences with 256 image tokens
  max_epochs: 3         # Start with fewer epochs to validate fixes work
  batch_size: 4         # Reduced due to longer sequences (256 image + text tokens)
  accumulate_grad_batches: 8  # Effective batch size = 4 * 8 = 32
  gradient_clip_val: 1.0

  # Learning rates - better balance for multimodal
  lora_lr: 2e-4         # Slightly lower for stability with more visual info
  projector_lr: 1e-3    # Projector learns vision-language alignment
  weight_decay: 0.01
  warmup_ratio: 0.1     # More warmup for stability
  
  # Validation
  val_check_interval: 0.5  # Check validation every half epoch
  limit_val_batches: 100   # Limit validation batches for speed
  
  # Checkpointing
  save_top_k: 3
  monitor: "val/loss"
  mode: "min"
  
  # Precision and optimization
  precision: "bf16-mixed"  # Use mixed precision for A100
  strategy: "auto"  # Let Lightning choose the best strategy
  
  # Early stopping
  patience: 2
  min_delta: 0.001
  
  # Sample generation during training (for early diagnosis!)
  # Generates sample outputs every N steps so you can SEE if model is learning
  sample_every_n_steps: 200  # Generate samples every 200 steps (adjust as needed)

# Lightning Trainer settings
trainer:
  accelerator: "gpu"
  devices: 1  # Single GPU training
  num_nodes: 1
  log_every_n_steps: 10
  enable_checkpointing: true
  enable_progress_bar: true
  enable_model_summary: true
  
  # Debugging and profiling
  fast_dev_run: false
  overfit_batches: 0
  detect_anomaly: false
  
  # Reproducibility
  deterministic: false  # Set to true for reproducible results (slower)
  benchmark: true       # Optimize for consistent input sizes

# Optimization settings
optimization:
  compile_model: false  # Set to true for PyTorch 2.0+ compilation
  use_fused_adamw: true # Use fused AdamW for better performance
  
# Logging and monitoring
logging:
  # Weights & Biases (recommended for visualization)
  use_wandb: false  # Set to true and add WANDB_API_KEY
  wandb_project: "multimodal-gemma"
  wandb_name: "gemma-270m-llava-training"
  log_model: false

  # TensorBoard (local visualization)
  use_tensorboard: true
  tb_log_dir: "logs/tensorboard"
  
  # MLflow (optional - for experiment tracking)
  use_mlflow: false
  mlflow_tracking_uri: "logs/mlflow"
  mlflow_experiment_name: "multimodal-gemma"

